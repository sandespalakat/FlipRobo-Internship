{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Scrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "from selenium import webdriver\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import urllib\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import pandas as pd\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "j = 0\n",
    "k = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a method to scrap images from amazon\n",
    "def get_images(url, folder, limit):\n",
    "    global j,k\n",
    "    j += 1\n",
    "    headers = { 'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/84.0.4147.89 Safari/537.36'}\n",
    "    response = requests.post(url, headers=headers)\n",
    "    soup = BeautifulSoup(response.content, \"lxml\")\n",
    "    rows = soup.find_all(\"img\", {\"data-image-latency\":\"s-product-image\"})\n",
    "    for row in rows:\n",
    "        k += 1\n",
    "        img_urls.append(row[\"src\"])\n",
    "        #getting the image from url\n",
    "        resp = requests.get(row[\"src\"])\n",
    "        #saving the image in the data folder\n",
    "        file = open( \"Data/\" +folder + \"/\"+str(k)+\".png\", \"wb\")\n",
    "        file.write(resp.content)\n",
    "        file.close()\n",
    "        img = Image.open(r\"Data/\" +folder + \"/\"+str(k)+\".png\")\n",
    "        img = img.resize((214, 320), Image.ANTIALIAS)\n",
    "        img.save( \"Data/\" +folder + \"/\"+str(k)+\".png\")\n",
    "        #flip the saved image to create a new image data\n",
    "        img2 = img.transpose(method=Image.FLIP_LEFT_RIGHT)\n",
    "        k += 1\n",
    "        img2.save( \"Data/\" +folder + \"/\"+str(k)+\".png\")\n",
    "        # Shows the image in image viewer\n",
    "#         im1.show()\n",
    "#         print(row[\"src\"])\n",
    "    next = soup.find(\"li\", {\"class\": \"a-last\"})\n",
    "    if next != None:\n",
    "        next_url = \"https://www.amazon.in\" + next.a.get(\"href\")\n",
    "        if j <= limit:\n",
    "            get_images(next_url, folder, limit)\n",
    "get_images(\"https://www.amazon.in/s?k=sarees&ref=nb_sb_noss_2\", \"sarees\", 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_images(\"https://www.amazon.in/s?k=jeans+men&crid=2BAPA2DF61FL6&sprefix=jeans%2Caps%2C327&ref=nb_sb_ss_ts-doa-p_1_5\", \\\n",
    "           \"jeans\", 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_images(\n",
    "    \"https://www.amazon.in/s?k=trousers&ref=nb_sb_noss_2\", \\\n",
    "           \"trousers\", 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
