{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in d:\\program_files\\anaconda\\lib\\site-packages (3.141.0)\n",
      "Requirement already satisfied: urllib3 in d:\\program_files\\anaconda\\lib\\site-packages (from selenium) (1.25.9)\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing required libraries\n",
    "from selenium import webdriver\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Q1: Write a python program to scrape data for “Data Analyst” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name, experience_required. You have to scrape first 10 jobs data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             title  \\\n",
      "0               Associate Systems and Data Analyst   \n",
      "1               Consultant-Data Analyst -Bangalore   \n",
      "2  Data Scientist / Data Analyst -Business Analyst   \n",
      "3                                     Data Analyst   \n",
      "4   Hiring For Data Analyst @ Flipkart on Contract   \n",
      "5                                     Data Analyst   \n",
      "6                    Deputy Manager - Data Analyst   \n",
      "7                              Senior Data Analyst   \n",
      "8                Data Analyst / Business Analyst -   \n",
      "9                            Business Data Analyst   \n",
      "\n",
      "                                            location  \\\n",
      "0                                Bangalore/Bengaluru   \n",
      "1                                Bangalore/Bengaluru   \n",
      "2  Mumbai, Hyderabad/Secunderabad, Pune, Gurgaon/...   \n",
      "3                                Bangalore/Bengaluru   \n",
      "4                                Bangalore/Bengaluru   \n",
      "5                                Bangalore/Bengaluru   \n",
      "6                                Bangalore/Bengaluru   \n",
      "7                                Bangalore/Bengaluru   \n",
      "8                       Chennai, Bangalore/Bengaluru   \n",
      "9                                Bangalore/Bengaluru   \n",
      "\n",
      "                                comapny experience  \n",
      "0                                Boeing    0-4 Yrs  \n",
      "1  Innovsource Services Private Limited    2-7 Yrs  \n",
      "2    Inflexion Analytix Private Limited    0-3 Yrs  \n",
      "3     Flipkart Internet Private Limited    1-3 Yrs  \n",
      "4     Flipkart Internet Private Limited    2-6 Yrs  \n",
      "5                IBM India Pvt. Limited    3-7 Yrs  \n",
      "6    Schneider Electric India Pvt. Ltd.    3-6 Yrs  \n",
      "7     Flipkart Internet Private Limited    2-5 Yrs  \n",
      "8  LatentView Analytics Private Limited    1-5 Yrs  \n",
      "9                  ALSTOM India Limited   5-10 Yrs  \n"
     ]
    }
   ],
   "source": [
    "driver = webdriver.Chrome(r\"C:\\Users\\DEVASREE\\Downloads\\chromedriver.exe\")\n",
    "url = \"https://www.naukri.com/\"\n",
    "driver.get(url)\n",
    "\n",
    "#finding the search fields, filling with the required inputs\n",
    "search_field = driver.find_element_by_name(\"keyword\")\n",
    "search_field.send_keys(\"Data Analyst\")\n",
    "location = driver.find_element_by_name(\"location\")\n",
    "location.send_keys(\"Bangalore\")\n",
    "\n",
    "#clicking the search button\n",
    "search_btn = driver.find_element_by_class_name(\"btn\")\n",
    "search_btn.click()\n",
    "\n",
    "time.sleep(20)\n",
    "\n",
    "#getting the list of job articles\n",
    "jobs = driver.find_elements_by_xpath(\"//article\")\n",
    "titles = []\n",
    "locations = []\n",
    "comapnies = []\n",
    "experience = []\n",
    "\n",
    "#looping through the first 10 jobs\n",
    "for job in jobs[0:10]:\n",
    "    titles.append(job.find_element_by_class_name(\"title\").text.strip())\n",
    "    locations.append(job.find_elements_by_class_name(\"ellipsis\")[4].text.strip())\n",
    "    comapnies.append(job.find_elements_by_class_name(\"ellipsis\")[1].text.strip())\n",
    "    experience.append(job.find_elements_by_class_name(\"ellipsis\")[2].text.strip())\n",
    "\n",
    "#creating the dataframe using the above info. \n",
    "jobs = pd.DataFrame()\n",
    "jobs[\"title\"] = titles\n",
    "jobs[\"location\"] = locations\n",
    "jobs[\"comapny\"] = comapnies\n",
    "jobs[\"experience\"] = experience\n",
    "print(jobs)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Q2: Write a python program to scrape data for “Data Scientist” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name, full job-description. You have to scrape first 10 jobs data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             title  \\\n",
      "0               Associate Systems and Data Analyst   \n",
      "1               Consultant-Data Analyst -Bangalore   \n",
      "2  Data Scientist / Data Analyst -Business Analyst   \n",
      "3                                     Data Analyst   \n",
      "4   Hiring For Data Analyst @ Flipkart on Contract   \n",
      "5                                     Data Analyst   \n",
      "6                    Deputy Manager - Data Analyst   \n",
      "7                              Senior Data Analyst   \n",
      "8                Data Analyst / Business Analyst -   \n",
      "9                            Business Data Analyst   \n",
      "\n",
      "                                            location  \\\n",
      "0                                Bangalore/Bengaluru   \n",
      "1                                Bangalore/Bengaluru   \n",
      "2  Mumbai, Hyderabad/Secunderabad, Pune, Gurgaon/...   \n",
      "3                                Bangalore/Bengaluru   \n",
      "4                                Bangalore/Bengaluru   \n",
      "5                                Bangalore/Bengaluru   \n",
      "6                                Bangalore/Bengaluru   \n",
      "7                                Bangalore/Bengaluru   \n",
      "8                       Chennai, Bangalore/Bengaluru   \n",
      "9                                Bangalore/Bengaluru   \n",
      "\n",
      "                                company  \\\n",
      "0                                Boeing   \n",
      "1  Innovsource Services Private Limited   \n",
      "2    Inflexion Analytix Private Limited   \n",
      "3     Flipkart Internet Private Limited   \n",
      "4     Flipkart Internet Private Limited   \n",
      "5                IBM India Pvt. Limited   \n",
      "6    Schneider Electric India Pvt. Ltd.   \n",
      "7     Flipkart Internet Private Limited   \n",
      "8  LatentView Analytics Private Limited   \n",
      "9                  ALSTOM India Limited   \n",
      "\n",
      "                                         description  \n",
      "0  Associate Systems and Data Analyst\\nThe select...  \n",
      "1  Roles and Responsibilities\\nCandidate must hav...  \n",
      "2  Job Role : Data Scientist/Data Analyst /Busine...  \n",
      "3  About the role:\\nData Analyst is an Individual...  \n",
      "4  Roles and Responsibilities\\nGather user requir...  \n",
      "5  You are a Data Analyst, who will be responsibl...  \n",
      "6  Job Description\\nThe Person is a front-line co...  \n",
      "7  Job Description:\\nThe candidate should have go...  \n",
      "8  Hi All,\\n\\nWe are hiring passionate Data / Bus...  \n",
      "9  Purpose of the role\\nReporting to the Data Man...  \n"
     ]
    }
   ],
   "source": [
    "driver = webdriver.Chrome(r\"C:\\Users\\DEVASREE\\Downloads\\chromedriver.exe\")\n",
    "url = \"https://www.naukri.com/\"\n",
    "driver.get(url)\n",
    "#finding and filling search fields and click submit button\n",
    "search_field = driver.find_element_by_name(\"keyword\")\n",
    "search_field.send_keys(\"Data Analyst\")\n",
    "location = driver.find_element_by_name(\"location\")\n",
    "location.send_keys(\"Bangalore\")\n",
    "search_btn = driver.find_element_by_class_name(\"btn\")\n",
    "search_btn.click()\n",
    "\n",
    "time.sleep(10)\n",
    "#finding the job div elements by xpath\n",
    "jobs = driver.find_elements_by_xpath(\"//article\")\n",
    "titles = []\n",
    "locations = []\n",
    "companies = []\n",
    "descriptions = []\n",
    "job_urls = []\n",
    "#looping through the first 10 job divs to get the reqd info\n",
    "for job in jobs[0:10]:\n",
    "    titles.append(job.find_element_by_class_name(\"title\").text.strip())\n",
    "    locations.append(job.find_elements_by_class_name(\"ellipsis\")[4].text.strip())\n",
    "    companies.append(job.find_elements_by_class_name(\"ellipsis\")[1].text.strip())\n",
    "    job_urls.append(job.find_element_by_class_name(\"title\").get_attribute(\"href\"))\n",
    "#go tot the detail job description to fetch remaining details\n",
    "for job_url in job_urls:\n",
    "    driver.get(job_url)\n",
    "    time.sleep(10)\n",
    "    try:\n",
    "        descriptions.append(driver.find_element_by_class_name(\"dang-inner-html\").text.strip())\n",
    "    except Exception as e:\n",
    "        descriptions.append(driver.find_element_by_class_name(\"clearboth\").text.strip())\n",
    "        \n",
    "#creating the dataframe using the above details\n",
    "det_jobs = pd.DataFrame()\n",
    "det_jobs[\"title\"] = titles\n",
    "det_jobs[\"location\"] = locations\n",
    "det_jobs[\"company\"] = companies\n",
    "det_jobs[\"description\"] = descriptions\n",
    "data = list(zip(titles,locations,companies,descriptions))\n",
    "print(pd.DataFrame(data=data, columns=[\"title\", \"location\", \"company\", \"description\"]))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Q3: In this question you have to scrape data using the filters available on the webpage as shown below:\n",
    "You have to use the location and salary filter.\n",
    "You have to scrape data for “Data Scientist” designation for first 10 job results.\n",
    "You have to scrape the job-title, job-location, company_name, experience_required.\n",
    "The location filter to be used is “Delhi/NCR”\n",
    "The salary filter to be used is “3-6” lakhs\n",
    "The task will be done as shown in the below steps:\n",
    "1. first get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Scientist” in “Skill,Designations,Companies” field .\n",
    "3. Then click the search button.\n",
    "4. Then apply the location filter and salary filter by checking the respective boxes\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               title  \\\n",
      "0    Data Scientist / Data Analyst -Business Analyst   \n",
      "1       Data Science Analyst-Insurance Data Sciences   \n",
      "2                              Business Data Analyst   \n",
      "3    Data & Business Analyst (Remote/Work from Home)   \n",
      "4  Business Analytics / Data Analyst / Fresher An...   \n",
      "5                                       Data Analyst   \n",
      "6                                       Data Analyst   \n",
      "7                       Data Engineer / Data Analyst   \n",
      "8                                       Data Analyst   \n",
      "9                                       Data Analyst   \n",
      "\n",
      "                                            location  \\\n",
      "0  Mumbai, Hyderabad/Secunderabad, Pune, Gurgaon/...   \n",
      "1                                   Gurgaon/Gurugram   \n",
      "2                                   Gurgaon/Gurugram   \n",
      "3  Kochi/Cochin, Kolkata, Hyderabad/Secunderabad,...   \n",
      "4               Noida, Gurgaon/Gurugram, Delhi / NCR   \n",
      "5                   Bangalore/Bengaluru, Delhi / NCR   \n",
      "6                                        Delhi / NCR   \n",
      "7                                   Gurgaon/Gurugram   \n",
      "8                                        Delhi / NCR   \n",
      "9                                   Gurgaon/Gurugram   \n",
      "\n",
      "                              comapny experience  \n",
      "0  Inflexion Analytix Private Limited    0-3 Yrs  \n",
      "1                           Xceedance    0-2 Yrs  \n",
      "2  RBS Services India Private Limited    2-5 Yrs  \n",
      "3              AINE Info Tech Pvt Ltd    0-2 Yrs  \n",
      "4           GABA Consultancy services    0-5 Yrs  \n",
      "5        Bytech India Private Limited    3-4 Yrs  \n",
      "6                       Stanza Living    1-4 Yrs  \n",
      "7                         Adglobal360    2-5 Yrs  \n",
      "8                            Snaphunt    2-5 Yrs  \n",
      "9                            NTT Data    2-4 Yrs  \n"
     ]
    }
   ],
   "source": [
    "driver = webdriver.Chrome(r\"C:\\Users\\DEVASREE\\Downloads\\chromedriver.exe\")\n",
    "url = \"https://www.naukri.com/\"\n",
    "driver.get(url)\n",
    "#fill the search field and click submit\n",
    "search_field = driver.find_element_by_name(\"keyword\")\n",
    "search_field.send_keys(\"Data Analyst\")\n",
    "search_btn = driver.find_element_by_class_name(\"btn\")\n",
    "search_btn.click()\n",
    "\n",
    "time.sleep(5)\n",
    "#finding the checkboxes for checking delhi in location and 3-6 in salaries\n",
    "locations = driver.find_elements_by_class_name(\"chckBoxCont\")\n",
    "for loc in locations:\n",
    "    if 'delhi' in loc.text.lower():\n",
    "        loc.click()\n",
    "        time.sleep(5)\n",
    "        break\n",
    "salaries = driver.find_elements_by_class_name(\"chckBoxCont\")\n",
    "for loc in salaries:\n",
    "    if '3-6' in loc.text.lower():\n",
    "        loc.click()\n",
    "        time.sleep(2)\n",
    "        break\n",
    "#finding the job div elements by xpath\n",
    "jobs = driver.find_elements_by_xpath(\"//article\")\n",
    "titles = []\n",
    "locations = []\n",
    "comapnies = []\n",
    "experience = []\n",
    "\n",
    "#looping through the first 10 jobs\n",
    "for job in jobs[0:10]:\n",
    "    titles.append(job.find_element_by_class_name(\"title\").text.strip())\n",
    "    locations.append(job.find_elements_by_class_name(\"ellipsis\")[4].text.strip())\n",
    "    comapnies.append(job.find_elements_by_class_name(\"ellipsis\")[1].text.strip())\n",
    "    experience.append(job.find_elements_by_class_name(\"ellipsis\")[2].text.strip())\n",
    "\n",
    "#creating the dataframe using the above info.\n",
    "jobs = pd.DataFrame()\n",
    "jobs[\"title\"] = titles\n",
    "jobs[\"location\"] = locations\n",
    "jobs[\"comapny\"] = comapnies\n",
    "jobs[\"experience\"] = experience\n",
    "print(jobs)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Q4: Write a python program to scrape data for first 10 job results for Data scientist Designation in Noida location. You have to scrape company_name, No. of days ago when job was posted, Rating of the company.\n",
    "This task will be done in following steps:\n",
    "1. first get the webpage https://www.glassdoor.co.in/index.htm\n",
    "2. Enter “Data Scientist” in “Job Title,Keyword,Company” field and enter “Noida” in “location” field.\n",
    "3. Then click the search button. You will land up in the below page\n",
    "4. Then scrape the data for the first 10 jobs results you get in the above shown page.\n",
    "5. Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Firefox(executable_path = r\"C:\\Users\\DEVASREE\\Downloads\\geckodriver.exe\")\n",
    "url = \"https://www.glassdoor.co.in/index.htm\"\n",
    "driver.get(url)\n",
    "time.sleep(3)\n",
    "#logged in manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#entered the information to search \n",
    "search = driver.find_element_by_id(\"sc.keyword\")\n",
    "search.clear()\n",
    "search.send_keys(\"Data Scientist\")\n",
    "location = driver.find_element_by_id(\"sc.location\")\n",
    "time.sleep(5)\n",
    "location.clear()\n",
    "location.send_keys(\"Noida\")\n",
    "submit = driver.find_element_by_class_name(\"gd-ui-button\")\n",
    "submit.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Days_ago</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Amploy</td>\n",
       "      <td>--</td>\n",
       "      <td>24h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mogli Labs India Private Limited</td>\n",
       "      <td>4.0</td>\n",
       "      <td>24h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Crowe</td>\n",
       "      <td>3.8</td>\n",
       "      <td>24h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ericsson</td>\n",
       "      <td>4.1</td>\n",
       "      <td>24h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Techlive</td>\n",
       "      <td>--</td>\n",
       "      <td>24h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Biz2Credit Inc</td>\n",
       "      <td>3.6</td>\n",
       "      <td>24h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LetsDressUp</td>\n",
       "      <td>--</td>\n",
       "      <td>24h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Jubna</td>\n",
       "      <td>--</td>\n",
       "      <td>24h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ANI Calls India Private Limited</td>\n",
       "      <td>--</td>\n",
       "      <td>24h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SearchUrCollege</td>\n",
       "      <td>--</td>\n",
       "      <td>24h</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Company Ratings Days_ago\n",
       "0                            Amploy      --      24h\n",
       "1  Mogli Labs India Private Limited     4.0      24h\n",
       "2                             Crowe     3.8      24h\n",
       "3                          Ericsson     4.1      24h\n",
       "4                          Techlive      --      24h\n",
       "5                    Biz2Credit Inc     3.6      24h\n",
       "6                       LetsDressUp      --      24h\n",
       "7                             Jubna      --      24h\n",
       "8   ANI Calls India Private Limited      --      24h\n",
       "9                   SearchUrCollege      --      24h"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#initialize the information list to create the dataframe\n",
    "companies = []\n",
    "ratings = []\n",
    "days_ago = []\n",
    "\n",
    "#find the job elements by class name\n",
    "joblist = driver.find_elements_by_class_name(\"react-job-listing\")\n",
    "\n",
    "#looping throught the first 10 jobs\n",
    "for i in joblist[0:10]:\n",
    "    #appending the information to the above created lists\n",
    "    try:\n",
    "        companies.append(i.find_elements_by_class_name(\"jobLink\")[1].text)\n",
    "    except:\n",
    "        companies.append(\"--\")\n",
    "    try:\n",
    "        ratings.append(i.find_element_by_class_name(\"css-19pjha7\").text)\n",
    "    except:\n",
    "        ratings.append(\"--\")\n",
    "    try:\n",
    "        days_ago.append(i.find_element_by_xpath(\"//div[@data-test='job-age']\").text)\n",
    "    except:\n",
    "        days_ago.append(\"--\")\n",
    "\n",
    "time.sleep(5)        \n",
    " # creating the dataframe\n",
    "jobs = pd.DataFrame({\"Company\":companies,\"Ratings\":ratings,\"Days_ago\":days_ago})\n",
    "jobs"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Q5: Write a python program to scrape the salary data for Data Scientist designation in Noida location.\n",
    "You have to scrape Company name, Number of salaries, Average salary, Min salary, Max Salary.\n",
    "The above task will be, done as shown in the below steps:\n",
    "1. first get the webpage https://www.glassdoor.co.in/Salaries/index.htm\n",
    "2. Enter “Data Scientist” in Job title field and “Noida” in location field.\n",
    "3. Click the search button.\n",
    "4. After that you will land on the below page\n",
    "You have to scrape whole data from this webpage\n",
    "5. Scrape data for first 10 companies. Scrape the min salary, max salary, company name, Average salary and rating of the company.\n",
    "6.Store the data in a dataframe.\n",
    "Note that all of the above steps have to be done by coding only and not manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Firefox(executable_path = r\"C:\\Users\\DEVASREE\\Downloads\\geckodriver.exe\")\n",
    "url = \"https://www.glassdoor.co.in/index.htm\"\n",
    "driver.get(url)\n",
    "time.sleep(3)\n",
    "#logged in manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>Min Salary</th>\n",
       "      <th>Max Salary</th>\n",
       "      <th>Avg Salary</th>\n",
       "      <th>No. of salaries</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>₹343K</td>\n",
       "      <td>₹1,250K</td>\n",
       "      <td>₹ 6,14,306</td>\n",
       "      <td>17 salaries</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>₹586K</td>\n",
       "      <td>₹2,730K</td>\n",
       "      <td>₹ 9,00,000</td>\n",
       "      <td>15 salaries</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>₹577K</td>\n",
       "      <td>₹2,213K</td>\n",
       "      <td>₹ 11,46,533</td>\n",
       "      <td>14 salaries</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>₹355K</td>\n",
       "      <td>₹1,613K</td>\n",
       "      <td>₹ 7,38,057</td>\n",
       "      <td>14 salaries</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>₹450K</td>\n",
       "      <td>₹11,622K</td>\n",
       "      <td>₹ 12,39,781</td>\n",
       "      <td>14 salaries</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>₹1,069K</td>\n",
       "      <td>₹1,520K</td>\n",
       "      <td>₹ 13,36,142</td>\n",
       "      <td>11 salaries</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>₹502K</td>\n",
       "      <td>₹1,465K</td>\n",
       "      <td>₹ 8,15,192</td>\n",
       "      <td>9 salaries</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>₹202K</td>\n",
       "      <td>₹1,809K</td>\n",
       "      <td>₹ 11,35,221</td>\n",
       "      <td>8 salaries</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>₹575K</td>\n",
       "      <td>₹1,520K</td>\n",
       "      <td>₹ 11,44,243</td>\n",
       "      <td>8 salaries</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>₹1,014K</td>\n",
       "      <td>₹2,149K</td>\n",
       "      <td>₹ 14,13,288</td>\n",
       "      <td>8 salaries</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Company Min Salary Max Salary   Avg Salary No. of salaries\n",
       "0  Data Scientist      ₹343K    ₹1,250K   ₹ 6,14,306     17 salaries\n",
       "1  Data Scientist      ₹586K    ₹2,730K   ₹ 9,00,000     15 salaries\n",
       "2  Data Scientist      ₹577K    ₹2,213K  ₹ 11,46,533     14 salaries\n",
       "3  Data Scientist      ₹355K    ₹1,613K   ₹ 7,38,057     14 salaries\n",
       "4  Data Scientist      ₹450K   ₹11,622K  ₹ 12,39,781     14 salaries\n",
       "5  Data Scientist    ₹1,069K    ₹1,520K  ₹ 13,36,142     11 salaries\n",
       "6  Data Scientist      ₹502K    ₹1,465K   ₹ 8,15,192      9 salaries\n",
       "7  Data Scientist      ₹202K    ₹1,809K  ₹ 11,35,221      8 salaries\n",
       "8  Data Scientist      ₹575K    ₹1,520K  ₹ 11,44,243      8 salaries\n",
       "9  Data Scientist    ₹1,014K    ₹2,149K  ₹ 14,13,288      8 salaries"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#redirect to the salary section\n",
    "driver.get(\"https://www.glassdoor.co.in/Salaries/index.htm\")\n",
    "#finding the search element, fill and click the search button\n",
    "search = driver.find_element_by_id(\"KeywordSearch\")\n",
    "search.clear()\n",
    "search.send_keys(\"Data Scientist\")\n",
    "location = driver.find_element_by_id(\"LocationSearch\")\n",
    "time.sleep(5)\n",
    "location.clear()\n",
    "location.send_keys(\"Noida\")\n",
    "submit = driver.find_element_by_id(\"HeroSearchButton\")\n",
    "submit.click()\n",
    "time.sleep(8)\n",
    "#finding the div elements which contains individual job info\n",
    "job_divs = driver.find_elements_by_xpath(\"//div[@data-test='salary-list-items']\")\n",
    "#initialize the information list to create the dataframe\n",
    "min_salary = []\n",
    "max_salary = []\n",
    "company_name = []\n",
    "avg_salary = []\n",
    "rating = []\n",
    "#looping through the first 10 salaries\n",
    "for job in job_divs[0:10]:\n",
    "    #appending the information to the above created lists\n",
    "    try:\n",
    "        salary = job.find_element_by_class_name(\"common__RangeBarStyle__values\").find_elements_by_tag_name(\"span\")\n",
    "        min_salary.append(salary[0].text)\n",
    "        max_salary.append(salary[1].text)\n",
    "    except Exception as e:\n",
    "        min_salary.append(\"--\")\n",
    "        max_salary.append(\"--\")\n",
    "    try:\n",
    "        company_name.append(job.find_element_by_class_name(\"m-0\").text)\n",
    "    except Exception as e:\n",
    "        company_name.append(\"--\")\n",
    "    try:\n",
    "        avg_salary.append(job.find_element_by_class_name(\"d-md-flex\").text.split(\"\\n\")[0])\n",
    "    except Exception as e:\n",
    "        avg_salary.append(\"--\")\n",
    "    try:\n",
    "        rating.append(job.find_element_by_class_name(\"css-1uyte9r\").text)\n",
    "    except Exception as e:\n",
    "        rating.append(\"--\")\n",
    "        \n",
    "#creating dataframe\n",
    "salaies = pd.DataFrame({\"Company\":company_name, \"Min Salary\":min_salary,\"Max Salary\":max_salary,\n",
    "                        \"Avg Salary\":avg_salary, \"No. of salaries\":rating})\n",
    "salaies\n",
    "    "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Q6 : Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes:\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price\n",
    "4. Discount %\n",
    "The attributes which you have to scrape is ticked marked in the below image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(executable_path = r\"C:\\Users\\DEVASREE\\Downloads\\chromedriver.exe\")\n",
    "url = \"https://www.flipkart.com\"\n",
    "driver.get(url)\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#put the query on the earch field and click\n",
    "query = driver.find_element_by_name('q')\n",
    "query.clear()\n",
    "query.send_keys(\"sunglasses\")\n",
    "g = driver.find_element_by_class_name('L0Z3Pu')\n",
    "g.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initilize product info lists\n",
    "brands = []\n",
    "descriptions = []\n",
    "prices = []\n",
    "discounts = []\n",
    "\n",
    "#looping through the first 3 pages to get 100 products\n",
    "for i in range(0,3):\n",
    "    time.sleep(5)\n",
    "    #getting the information div by class\n",
    "    divs = driver.find_elements_by_class_name('_2B099V')\n",
    "    #looping through each products\n",
    "    for div in divs:\n",
    "        #appending info to the currsponding lists\n",
    "        brands.append(div.find_element_by_class_name('_2WkVRV').text)\n",
    "        descriptions.append(div.find_element_by_class_name('IRpwTa').text)\n",
    "        prices.append(div.find_element_by_class_name('_30jeq3').text)\n",
    "        discounts.append(div.find_element_by_class_name('_3Ay6Sb').text.strip(\" off\"))\n",
    "    next_page = driver.find_elements_by_xpath(\"//a[@class='_1LKTO3']\")\n",
    "    try:\n",
    "        #go to next page\n",
    "        driver.get(next_page[1].get_attribute('href'))\n",
    "    except:\n",
    "        driver.get(next_page[0].get_attribute('href'))\n",
    "\n",
    "#creatinf dataframe\n",
    "glasses = pd.DataFrame({'Brand':brands[:100],\n",
    "                'Description':descriptions[:100],\n",
    "                'Price':prices[:100],\n",
    "                'Discount':discounts[:100]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Description</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Rectangular Sunglasses (Free Size)</td>\n",
       "      <td>₹570</td>\n",
       "      <td>28%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NuVew</td>\n",
       "      <td>UV Protection Aviator Sunglasses (57)</td>\n",
       "      <td>₹185</td>\n",
       "      <td>76%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Silver Kartz</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (Free Size)</td>\n",
       "      <td>₹246</td>\n",
       "      <td>83%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PIRASO</td>\n",
       "      <td>UV Protection Aviator Sunglasses (54)</td>\n",
       "      <td>₹225</td>\n",
       "      <td>85%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ROZZETTA CRAFT</td>\n",
       "      <td>UV Protection Retro Square Sunglasses (Free Size)</td>\n",
       "      <td>₹499</td>\n",
       "      <td>77%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Aviator Sunglasses (58)</td>\n",
       "      <td>₹1,148</td>\n",
       "      <td>11%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (Free Size)</td>\n",
       "      <td>₹758</td>\n",
       "      <td>15%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (57)</td>\n",
       "      <td>₹559</td>\n",
       "      <td>30%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>Gradient, UV Protection Wayfarer Sunglasses (F...</td>\n",
       "      <td>₹682</td>\n",
       "      <td>14%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (Free Size)</td>\n",
       "      <td>₹758</td>\n",
       "      <td>15%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Brand                                        Description   Price  \\\n",
       "0         Fastrack   UV Protection Rectangular Sunglasses (Free Size)    ₹570   \n",
       "1            NuVew              UV Protection Aviator Sunglasses (57)    ₹185   \n",
       "2     Silver Kartz      UV Protection Wayfarer Sunglasses (Free Size)    ₹246   \n",
       "3           PIRASO              UV Protection Aviator Sunglasses (54)    ₹225   \n",
       "4   ROZZETTA CRAFT  UV Protection Retro Square Sunglasses (Free Size)    ₹499   \n",
       "..             ...                                                ...     ...   \n",
       "95        Fastrack              UV Protection Aviator Sunglasses (58)  ₹1,148   \n",
       "96        Fastrack      UV Protection Wayfarer Sunglasses (Free Size)    ₹758   \n",
       "97        Fastrack             UV Protection Wayfarer Sunglasses (57)    ₹559   \n",
       "98        Fastrack  Gradient, UV Protection Wayfarer Sunglasses (F...    ₹682   \n",
       "99        Fastrack      UV Protection Wayfarer Sunglasses (Free Size)    ₹758   \n",
       "\n",
       "   Discount  \n",
       "0       28%  \n",
       "1       76%  \n",
       "2       83%  \n",
       "3       85%  \n",
       "4       77%  \n",
       "..      ...  \n",
       "95      11%  \n",
       "96      15%  \n",
       "97      30%  \n",
       "98      14%  \n",
       "99      15%  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glasses"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Q7: Scrape 100 reviews data from flipkart.com for iphone11 phone. You have to go the link: https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace.\n",
    "When you will open the above link you will reach to the below shown webpage.\n",
    "As shown in the above page you have to scrape the tick marked attributes.\n",
    "These are\n",
    "1. Rating\n",
    "2. Review_summary\n",
    "3. Full review\n",
    "You have to scrape this data for first 100 reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(executable_path = r\"C:\\Users\\DEVASREE\\Downloads\\chromedriver.exe\")\n",
    "url = \"https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace\"\n",
    "#go to the iphone url\n",
    "driver.get(url)\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#click on \"all reviews\" to expand the page\n",
    "all_reviews = driver.find_element_by_class_name(\"_3UAT2v\")\n",
    "all_reviews.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Rating    Short Description  \\\n",
      "0       5     Perfect product!   \n",
      "1       4      Worth the money   \n",
      "2       4            Wonderful   \n",
      "3       5     Perfect product!   \n",
      "4       4          Good choice   \n",
      "..    ...                  ...   \n",
      "95      5  Best in the market!   \n",
      "96      5            Must buy!   \n",
      "97      5            Just wow!   \n",
      "98      5    Worth every penny   \n",
      "99      5            Fabulous!   \n",
      "\n",
      "                                          Full review  \n",
      "0   A great device with a good battery backup that...  \n",
      "1   Awesome product!\\nBattery: awesome\\nDisplay: a...  \n",
      "2   I just loved the phone .... as I was waiting f...  \n",
      "3   Nice phone to buy with such offers its worth i...  \n",
      "4   One of my Fav Brand Apple and the Iphone 11 wa...  \n",
      "..                                                ...  \n",
      "95                                        Good Camera  \n",
      "96                                It’s really awesome  \n",
      "97                                  Perfect Product!!  \n",
      "98  Feeling awesome after getting the delivery of ...  \n",
      "99  It’s very good battery life and display and vi...  \n",
      "\n",
      "[100 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "#initilize review info lists\n",
    "ratings = []\n",
    "review_summ = []\n",
    "full_reviews = []\n",
    "\n",
    "# looping through 10 pages to get 100 reiews(10reviews/page)\n",
    "for i in range (0, 11):\n",
    "    #getting the information div by class\n",
    "    divs = driver.find_elements_by_class_name(\"_2wzgFH\")\n",
    "    for div in divs:\n",
    "        #appending info to the lists\n",
    "        ratings.append(div.find_element_by_class_name('_3LWZlK').text)\n",
    "        review_summ.append(div.find_element_by_class_name('_2-N8zT').text)\n",
    "        full_reviews.append(div.find_element_by_class_name('t-ZTKy').text)\n",
    "    next_page = driver.find_elements_by_xpath(\"//a[@class='_1LKTO3']\")\n",
    "    try:\n",
    "        #go to next page\n",
    "        driver.get(next_page[1].get_attribute('href'))\n",
    "    except:\n",
    "        driver.get(next_page[0].get_attribute('href'))\n",
    "#creatinf dataframe\n",
    "reviews = pd.DataFrame({'Rating':ratings[:100],\n",
    "                'Short Description':review_summ[:100],\n",
    "                'Full review':full_reviews[:100]})\n",
    "print(reviews)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Q8: Scrape data for first 100 sneakers you find when you visit flipkart.com and search for “sneakers” in the search field.\n",
    "You have to scrape 4 attributes of each sneaker :\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price\n",
    "4. discount %\n",
    "As shown in the below image, you have to scrape the tick marked attributes.\n",
    "Also note that all the steps required during scraping should be done through code only and not manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(executable_path = r\"C:\\Users\\DEVASREE\\Downloads\\chromedriver.exe\")\n",
    "url = \"https://www.flipkart.com\"\n",
    "#go to flipkart\n",
    "driver.get(url)\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#enter the keyword and submit\n",
    "query = driver.find_element_by_name('q')\n",
    "query.clear()\n",
    "query.send_keys(\"sneakers\")\n",
    "g = driver.find_element_by_class_name('L0Z3Pu')\n",
    "g.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initilize product info lists\n",
    "brands = []\n",
    "descriptions = []\n",
    "prices = []\n",
    "discounts = []\n",
    "\n",
    "#looping through 3 pages \n",
    "for i in range(0,3):\n",
    "    time.sleep(5)\n",
    "    #getting the information div by class\n",
    "    divs = driver.find_elements_by_class_name('_2B099V')\n",
    "    for div in divs:\n",
    "        #appending the info to the lists\n",
    "        brands.append(div.find_element_by_class_name('_2WkVRV').text)\n",
    "        descriptions.append(div.find_element_by_class_name('IRpwTa').text)\n",
    "        prices.append(div.find_element_by_class_name('_30jeq3').text)\n",
    "        discounts.append(div.find_element_by_xpath(\"//div[@class='_3Ay6Sb']\").text)\n",
    "    next_page = driver.find_elements_by_xpath(\"//a[@class='_1LKTO3']\")\n",
    "    try:\n",
    "        driver.get(next_page[1].get_attribute('href'))\n",
    "    except:\n",
    "        driver.get(next_page[0].get_attribute('href'))\n",
    "\n",
    "#creating dataframe\n",
    "sneakers = pd.DataFrame({'Brand':brands[:100],\n",
    "                'Description':descriptions[:100],\n",
    "                'Price':prices[:100],\n",
    "                'Discount':discounts[:100]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Description</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>World Wear Footwear</td>\n",
       "      <td>5011-Latest Collection Stylish Casual Loafer S...</td>\n",
       "      <td>₹240</td>\n",
       "      <td>51% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SPARX</td>\n",
       "      <td>Men White Sneakers Sneakers For Men</td>\n",
       "      <td>₹630</td>\n",
       "      <td>51% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PUMA</td>\n",
       "      <td>Ontario IDP Sneakers For Men</td>\n",
       "      <td>₹1,569</td>\n",
       "      <td>51% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PUMA</td>\n",
       "      <td>Anzarun Cage Sneakers For Men</td>\n",
       "      <td>₹2,239</td>\n",
       "      <td>51% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SPARX</td>\n",
       "      <td>SM-273 Sneakers For Men</td>\n",
       "      <td>₹1,000</td>\n",
       "      <td>51% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>well feet</td>\n",
       "      <td>sneaker for mens and boys Sneakers For Men</td>\n",
       "      <td>₹399</td>\n",
       "      <td>65% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>SHOEFLY</td>\n",
       "      <td>Combo Men Pack of 2 Loafers Shoes Sneakers For...</td>\n",
       "      <td>₹367</td>\n",
       "      <td>65% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>BRUTON</td>\n",
       "      <td>Combo Pack of 2 Casual Shoes Sneakers For Men</td>\n",
       "      <td>₹299</td>\n",
       "      <td>65% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>bluemaker</td>\n",
       "      <td>casual shoe for men Sneakers For Men</td>\n",
       "      <td>₹474</td>\n",
       "      <td>65% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>PUMA</td>\n",
       "      <td>Cape IDP Sneakers For Men</td>\n",
       "      <td>₹2,029</td>\n",
       "      <td>65% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Brand                                        Description  \\\n",
       "0   World Wear Footwear  5011-Latest Collection Stylish Casual Loafer S...   \n",
       "1                 SPARX                Men White Sneakers Sneakers For Men   \n",
       "2                  PUMA                       Ontario IDP Sneakers For Men   \n",
       "3                  PUMA                      Anzarun Cage Sneakers For Men   \n",
       "4                 SPARX                            SM-273 Sneakers For Men   \n",
       "..                  ...                                                ...   \n",
       "95            well feet         sneaker for mens and boys Sneakers For Men   \n",
       "96              SHOEFLY  Combo Men Pack of 2 Loafers Shoes Sneakers For...   \n",
       "97               BRUTON      Combo Pack of 2 Casual Shoes Sneakers For Men   \n",
       "98            bluemaker               casual shoe for men Sneakers For Men   \n",
       "99                 PUMA                          Cape IDP Sneakers For Men   \n",
       "\n",
       "     Price Discount  \n",
       "0     ₹240  51% off  \n",
       "1     ₹630  51% off  \n",
       "2   ₹1,569  51% off  \n",
       "3   ₹2,239  51% off  \n",
       "4   ₹1,000  51% off  \n",
       "..     ...      ...  \n",
       "95    ₹399  65% off  \n",
       "96    ₹367  65% off  \n",
       "97    ₹299  65% off  \n",
       "98    ₹474  65% off  \n",
       "99  ₹2,029  65% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sneakers"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Q9: Go to the link - https://www.myntra.com/shoes\n",
    "Set Price filter to “Rs. 6649 to Rs. 13099” , Color filter to “Black”, as shown in the below image\n",
    "And then scrape First 100 shoes data you get. The data should include “Brand” of the shoes , Short Shoe description, price of the shoe as shown in the below image.\n",
    "Please note that applying the filter and scraping the data , everything should be done through code only and there should not be any manual step.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(executable_path = r\"C:\\Users\\DEVASREE\\Downloads\\chromedriver.exe\")\n",
    "url = \"https://www.myntra.com/shoes\"\n",
    "#go to myntra shoe section\n",
    "driver.get(url)\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clicking the filter condition checkboxes\n",
    "price_el = driver.find_element_by_class_name(\"price-list\")\n",
    "price_el.find_elements_by_tag_name(\"li\")[1].click()\n",
    "driver.find_elements_by_class_name(\"colour-listItem\")[0].click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Brand                       Description Price\n",
      "0   Skechers     Men VIPER COMPETITOR Training  6999\n",
      "1       Geox         Men Leather Formal Derbys  8617\n",
      "2       Puma       Men UltraRide Running Shoes  7199\n",
      "3       Geox       Men Leather Formal Slip-Ons  8994\n",
      "4      Ruosh  Men Solid Leather Formal Oxfords  9443\n",
      "..       ...                               ...   ...\n",
      "95  RAPAWALK    Standard Width Leather Oxfords  7500\n",
      "96  RAPAWALK    Standard Width Leather Oxfords  7500\n",
      "97  RAPAWALK    Standard Width Leather Oxfords  7500\n",
      "98  RAPAWALK    Standard Width Leather Oxfords  7500\n",
      "99  RAPAWALK        Wide Width Leather Oxfords  7500\n",
      "\n",
      "[100 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "#initilize product info lists\n",
    "brands = []\n",
    "descriptions = []\n",
    "prices = []\n",
    "#looping to get 100 products(50 products/page)\n",
    "for i in range(0,2):\n",
    "    time.sleep(5)\n",
    "    #getting the information div by class\n",
    "    divs = driver.find_elements_by_class_name('product-productMetaInfo')\n",
    "    for div in divs:\n",
    "        #appending info to the lists\n",
    "        brands.append(div.find_element_by_class_name('product-brand').text)\n",
    "        descriptions.append(div.find_element_by_class_name('product-product').text)\n",
    "        prices.append(div.find_element_by_class_name(\"product-price\").text.split(\".\")[1].split(\"Rs\")[0].strip())\n",
    "    next_page = driver.find_elements_by_xpath(\"//a[@rel='next']\")\n",
    "    try:\n",
    "        driver.get(next_page[1].get_attribute('href'))\n",
    "    except:\n",
    "        driver.get(next_page[0].get_attribute('href'))\n",
    "\n",
    "# creating dataframe\n",
    "shoes = pd.DataFrame({'Brand':brands[:100],\n",
    "                'Description':descriptions[:100],\n",
    "                'Price':prices[:100]})\n",
    "print(shoes)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Q10: Go to webpage https://www.amazon.in/\n",
    "Enter “Laptop” in the search field and then click the search icon.\n",
    "Then set CPU Type filter to “Intel Core i7” and “Intel Core i9” as shown in the below image:\n",
    "After setting the filters scrape first 10 laptops data. You have to scrape 3 attributes for each laptop:\n",
    "1. title\n",
    "2. Ratings\n",
    "3. Price\n",
    "As shown in the below image as the tick marked attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(executable_path = r\"C:\\Users\\DEVASREE\\Downloads\\chromedriver.exe\")\n",
    "url = \"https://www.amazon.in/\"\n",
    "#going to amazon\n",
    "driver.get(url)\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#entering the product information and search\n",
    "search_field = driver.find_element_by_id(\"twotabsearchtextbox\")\n",
    "search_field.send_keys(\"Laptop\")\n",
    "search_button = driver.find_element_by_id(\"nav-search-submit-button\")\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find out the filtering check boxes\n",
    "filter_div = driver.find_element_by_id(\"filters\")\n",
    "filters = filter_div.find_elements_by_tag_name(\"li\")\n",
    "# search for the required checkboxes and mark as checked \n",
    "for flter in filters:\n",
    "    if \"i7\" in flter.text:\n",
    "        driver.get(flter.find_element_by_class_name(\"a-link-normal\").get_attribute('href'))\n",
    "        time.sleep(6)\n",
    "        break\n",
    "filter_div = driver.find_element_by_id(\"filters\")\n",
    "filters = filter_div.find_elements_by_tag_name(\"li\")\n",
    "for flter in filters:\n",
    "    if \"i9\" in flter.text:\n",
    "        driver.get(flter.find_element_by_class_name(\"a-link-normal\").get_attribute('href'))\n",
    "        time.sleep(6)\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               Title     Price Ratings\n",
      "0  HP Pavilion (2021) Thin & Light 11th Gen Core ...    84,990     4.4\n",
      "1  Mi Notebook Horizon Edition 14 Intel Core i5-1...    54,999     4.4\n",
      "2  HP Pavilion x360 (2021) 14\" (35.56cms) FHD Tou...    79,993     3.8\n",
      "3  ASUS VivoBook S S14 Intel Core i7-1165G7 11th ...    77,990     4.4\n",
      "4  Lenovo IdeaPad Gaming 3 10th Gen Intel Core i7...    77,990     4.4\n",
      "5  Lenovo IdeaPad Flex 5 11th Gen Intel Core i7 1...    88,990     4.1\n",
      "6  HP Pavilion Gaming 10th Gen Intel Core i7 Proc...    86,990     3.9\n",
      "7  (Renewed) Dell Latitude E6440 14 Inch Laptop (...    46,999     3.6\n",
      "8  ASUS ROG Strix G15 (2020), 15.6\" FHD 144Hz, In...  1,02,990     NaN\n",
      "9  Lenovo Yoga 7 11th Gen Intel Core i7 14\" (35.5...  1,01,990     4.5\n"
     ]
    }
   ],
   "source": [
    "time.sleep(5)\n",
    "#finding all individual product div elements\n",
    "divs = driver.find_elements_by_xpath(\"//div[@class='sg-row']\")\n",
    "#initialising product info lists\n",
    "titles = []\n",
    "ratings = []\n",
    "price = []\n",
    "#looping through the product divs(the first div is empty as per html)\n",
    "for div in divs[1:]:\n",
    "#     appending values to the lists\n",
    "    try:\n",
    "        titles.append(div.find_element_by_class_name(\"a-size-medium\").text)\n",
    "        #check title exists(the product div should contain heading)\n",
    "        if bool(div.find_element_by_class_name(\"a-size-medium\")):\n",
    "            try:\n",
    "                price.append(div.find_element_by_class_name(\"a-price-whole\").text)\n",
    "            except:\n",
    "                price.append(\"--\")\n",
    "            try:\n",
    "                ratings.append(div.find_element_by_class_name(\"a-icon-alt\")\n",
    "                               .get_attribute('innerHTML').split(\" \")[0])\n",
    "            except Exception as e:\n",
    "                    ratings.append(np.nan)\n",
    "    except Exception as e:\n",
    "        continue\n",
    "#creating dataframe\n",
    "laptops = pd.DataFrame({'Title':titles[:10],\n",
    "                'Price':price[:10],\n",
    "                'Ratings':ratings[:10]})\n",
    "print(laptops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
